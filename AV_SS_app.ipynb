{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import cv2\n",
    "\n",
    "# Deep Learning\n",
    "import torch # V1.5\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from av_semantic_segmentation_utils import ImgPreprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters and Definitions\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "BATCH_SIZE =  32\n",
    "NUM_WORKERS = 0\n",
    "NUM_EPOCHS = 20\n",
    "SEED = 42\n",
    "\n",
    "MAPILLARY_DATASET = '/mapillary_dataset/'\n",
    "SAMPLE_DATASET = 'research_samples/*/*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to run on GPU, this is important to save crucial time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "using_cuda = torch.cuda.is_available()\n",
    "print(using_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Import Datasets\n",
    "\n",
    "[Mapillary Dataset](https://www.mapillary.com/dataset/vistas?pKey=xyW6a0ZmrJtjLw2iJ71Oqg&lat=-20.802740852123236&lng=12.68482740542754&z=0.8773058425632839)\n",
    "\n",
    "- 25,000 high-resolution images\n",
    "- 152 object categories\n",
    "- 100 instance-specifically annotated categories\n",
    "- Global reach, covering 6 continents\n",
    "- Variety of weather, season, time of day, camera, and viewpoint\n",
    "\n",
    "<p align=\"right\">\n",
    "  <img src=\"img/distribution.png\" width=\"500\" title=\"distribution\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24 sample images.\n"
     ]
    }
   ],
   "source": [
    "sample_imgs = ImgPreprocessor(glob(SAMPLE_DATASET))\n",
    "\n",
    "print('There are %d sample images.' % sample_imgs.size)\n",
    "\n",
    "for i in range(0, int(len(sample_imgs.imgs)/2)):\n",
    "    f, axarr = plt.subplots(1,2, figsize=(15, 15))\n",
    "    axarr[0].imshow(cv2.cvtColor(sample_imgs.imgs[i*2], cv2.COLOR_BGR2RGB))\n",
    "    axarr[0].axis(\"off\")\n",
    "    axarr[1].imshow(cv2.cvtColor(sample_imgs.imgs[i*2+1], cv2.COLOR_BGR2RGB))\n",
    "    axarr[1].axis(\"off\")\n",
    "\n",
    "sample_imgs.pre_process(IMG_WIDTH, IMG_HEIGHT)\n",
    "sample_imgs.gaussian_blur()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
